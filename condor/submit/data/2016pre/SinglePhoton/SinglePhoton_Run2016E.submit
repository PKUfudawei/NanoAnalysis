# The UNIVERSE defines an execution environment. You will almost always use VANILLA. 
Universe = vanilla 

# +ProjectName is the name of the project reported to the OSG accounting system
+ProjectName = "cms.org.cern"

# Jobs which exceed the maximum runtime will be terminated
## "tomorrow" = 1 day
+JobFlavour = "testmatch"
JobBatchName = data/2016pre/SinglePhoton/SinglePhoton_Run2016E

# EXECUTABLE is the program your job will run It's often useful 
# to create a shell script to "wrap" your actual work. 
Executable = ./Execute.sh
Arguments = data_2016pre_SinglePhoton ./src/parameters/ $(file)

# Setting the should_transfer_files command explicitly enables 
# or disables the file transfer mechanism
should_transfer_files   = YES
transfer_input_files    = ../src
when_to_transfer_output = ON_EXIT_OR_EVICT
transfer_output_files   = output.parq, stats.yml
transfer_output_remaps  = "output.parq = output/data/2016pre/SinglePhoton/SinglePhoton_Run2016E/data_2016pre_SinglePhoton-$(Process).parq; stats.yml = output/data/2016pre/SinglePhoton/SinglePhoton_Run2016E/data_2016pre_SinglePhoton-$(Process).yml"
#output_destination = output_test/data/2016pre/SinglePhoton/SinglePhoton_Run2016E/ ## not tested yet

# If one wants to use local condor batch to analyze user/group skims 
# located at remote sites. The only modification needed is adding
use_x509userproxy       = true
# For OLDER versions of HTCondor (before 8.0.0), you need
# x509userproxy           = ~/.proxy

# ERROR and OUTPUT are the error and output channels from your job
# that HTCondor returns from the remote host.
# The LOG file is where HTCondor places information about your 
# job's status, success, and resource consumption. 
Error = log/data/2016pre/SinglePhoton/SinglePhoton_Run2016E/$(Cluster).$(Process).err
Output = log/data/2016pre/SinglePhoton/SinglePhoton_Run2016E/$(Cluster).$(Process).out
Log = log/data/2016pre/SinglePhoton/SinglePhoton_Run2016E/$(Cluster).log

# Specify CPU,Memory and Disk
# Default units if not specified:
# Disk: Kb, Memory:Mb
# Request_cpus = 3 ## requesting more cpu leads to more idle time
# Request_disk = 100 Mb
# Request_memory = 2048
Rank = Memory
# Rank = ( Memory>=32 ) * ( 10*Mips + 2*KFlops + 100*Memory + 8*VirtualMemory )

# QUEUE is the "start button" - it launches any jobs that have been 
# specified thus far. 
Queue file from filelists/data/2016pre/SinglePhoton/SinglePhoton_Run2016E.txt
